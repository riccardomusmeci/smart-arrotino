{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "from src.io.io import read_rgb\n",
    "import matplotlib.pyplot as plt\n",
    "from src.transform.transform import transform\n",
    "from src.dataset.road_dataset import RoadDataset\n",
    "from src.model.segmentation_module import RoadSegmentationModule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize(image: np.array, gt_mask: np.array, mask: np.array, category: list, ):\n",
    "    \"\"\"plots images in one row\n",
    "    \"\"\"\n",
    "    \n",
    "    plt.figure(figsize=(32, 9))\n",
    "    plt.subplot(1, 3, 1)\n",
    "    plt.title(f\"Grount Truth Image + Mask\")\n",
    "    color = np.array([20, 250, 10], dtype=np.uint8)\n",
    "    masked_img = np.where(gt_mask[..., None], color, image)\n",
    "    gt_image = cv2.addWeighted(image, 0.5, masked_img, 0.5, 0)\n",
    "    \n",
    "    plt.imshow(gt_image)\n",
    "    \n",
    "    plt.subplot(1, 3, 2)\n",
    "    plt.title(f\"Pred Mask for {category}\")\n",
    "    # mask = cv2.cvtColor(mask, cv2.COLOR_GRAY2RGB)\n",
    "    # masked_img = np.where(mask[...,None], color, img)\n",
    "    color = np.array([20, 250, 10], dtype=np.uint8)\n",
    "    masked_img = np.where(mask[..., None], color, image)\n",
    "    pred_image = cv2.addWeighted(image, 0.5, masked_img, 0.5, 0)\n",
    "    \n",
    "    plt.imshow(pred_image)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RoadSegmentationModule.load_from_checkpoint(\n",
    "    checkpoint_path=\"PATH/TO/BEST/CKPT\"\n",
    ")\n",
    "model.model.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = (512, 512)\n",
    "dataset = RoadDataset(\n",
    "    data_dir=\"PATH/TO/SPLIT/DATASET\",\n",
    "    classes=[\"CLASS\"],\n",
    "    train=False,\n",
    "    transform=transform(train=False, input_size=input_size)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = random.randint(0, len(dataset)-1)\n",
    "img_path = dataset.images[index]\n",
    "print(img_path)\n",
    "x, mask = dataset[index]\n",
    "\n",
    "preds = model(x.unsqueeze(0))\n",
    "preds = torch.sigmoid(preds)\n",
    "\n",
    "pred_mask = preds.squeeze().squeeze().detach().numpy()\n",
    "\n",
    "pred_mask[pred_mask>0.5] = 1\n",
    "pred_mask[pred_mask<=0.5] = 0\n",
    "\n",
    "image = read_rgb(file_path=img_path + \"_RAW.jpg\")\n",
    "image = cv2.resize(image, input_size)\n",
    "\n",
    "visualize(\n",
    "    image=image,\n",
    "    gt_mask=mask.detach().numpy().squeeze(),\n",
    "    mask=pred_mask,\n",
    "    category=\"crack\"\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "73c89cbd1933bceac1c956f0c1220af12e7bc5f0f009bc20d431726764063097"
  },
  "kernelspec": {
   "display_name": "Python 3.9.10 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
